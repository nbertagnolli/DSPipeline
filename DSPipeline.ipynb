{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data = x_train\n",
    "global_labels = y_train\n",
    "\n",
    "x_test = x_train[1000:2000]\n",
    "y_test = y_train[1000:2000]\n",
    "x_train = x_train[:1000]\n",
    "y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_input_simulator(x_train, y_train, x_test, y_test, global_data, global_labels, step_size = 1000):\n",
    "    \"\"\"\n",
    "    This method simulates getting more data in the wild.  It takes a set of training data\n",
    "    and testing data creates a new training set by combining the training and test set\n",
    "    and then sampling a new test set from the unused samples in global_data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combine the test set into the training set\n",
    "    new_train_data = np.concatenate([x_train, x_test], axis=0)\n",
    "    new_train_labels = np.concatenate([y_train, y_test], axis=0)\n",
    "    \n",
    "    new_num_samples = new_train_data.shape[0]\n",
    "    \n",
    "    # Extract a new test set from the global data\n",
    "    new_test_data = global_data[new_num_samples:new_num_samples + step_size]\n",
    "    new_test_labels = global_labels[new_num_samples:new_num_samples + step_size]\n",
    "    \n",
    "    return new_train_data, new_test_data, new_train_labels, new_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = data_input_simulator(x_train, y_train, x_test, y_test, global_data, global_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformers\n",
    "class FlattenTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Flatten an existing array into \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.reshape(X.shape[0], X.shape[1] * X.shape[2]).astype('float32') / 255\n",
    "    \n",
    "class ChannelTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Flatten an existing array into \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_rows, img_columns, img_channels, channels_first=False):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_columns = img_columns\n",
    "        self.img_channels = img_channels\n",
    "        self.channels_first = channels_first\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.channels_first:\n",
    "            return X.reshape(X.shape[0], 1, self.img_rows, self.img_cols).astype('float32') / 255\n",
    "        else:\n",
    "            return X.reshape(X.shape[0], self.img_rows, self.img_columns, self.img_channels).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:: Define NN based estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "        ('flatten', FlattenTransformer()),\n",
    "        ('classifier', svm.SVC(C=1, kernel='linear'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defin a Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "        ('flatten', FlattenTransformer()),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=25))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_staging_area():\n",
    "    \n",
    "    def __init__(self, models=None):\n",
    "        self.models = [] if not models else models\n",
    "        self.best_model = None\n",
    "        \n",
    "    def time_step_model_selection(self):\n",
    "        \"\"\"Retrains models and reevaluates them choosing a production model\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluates all models and returns the best one\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Uses the best model to predict on the data\"\"\"\n",
    "        return self.best_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
